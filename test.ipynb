{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <p style=\"text-align: center\"><b>Laaraib Ahmed\n",
    "### <p style=\"text-align: center\">Nust Student CS\n",
    "#### <p style=\"text-align: center;\">The following are the Web Scraping implementations as described in the sent mail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Pages of consisting of data are: 8\n",
      "gathered data for 1 element\n",
      "\n",
      "gathered data for 2 element\n",
      "\n",
      "gathered data for 3 element\n",
      "\n",
      "gathered data for 4 element\n",
      "\n",
      "gathered data for 5 element\n",
      "\n",
      "gathered data for 6 element\n",
      "\n",
      "gathered data for 7 element\n",
      "\n",
      "gathered data for 8 element\n",
      "\n",
      "end of fetching data\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "#Make a dictionary with classes for each attribute\n",
    "property_dict = {\"dict_prices\" : [],\"dict_address\" : [],\"dict_sqft\" :[],\"dict_acres\" : [],\"dict_url\" : [],\"dict_broker\" : [],}\n",
    "\n",
    "\n",
    "def fetch_url(url):\n",
    "    # Headers are used to make the request look like it is coming from a browser.\n",
    "    HEADERS = {\n",
    "        \"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.110 Safari/537.36\",\n",
    "        \"accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8\",\n",
    "        \"accept-language\": \"en-US;en;q=0.9\",\n",
    "        \"accept-encoding\": \"gzip, deflate, br\",\n",
    "    }\n",
    "    # Send an HTTP request to the URL.\n",
    "    response = requests.get(url, headers = HEADERS)\n",
    "    if response.status_code == 200:\n",
    "        # Parse the HTML content of the page\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        return soup\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the page. Status code:{response.status_code}\")\n",
    "        return None\n",
    "    \n",
    "soup=fetch_url(\"https://www.realtor.com/realestateandhomes-search/Brownwood_TX\")    \n",
    "total_strings=soup.find('div',{\"data-testid\":\"total-matching-properties\"}).get_text(strip=True)\n",
    "total_elements=re.findall(r'\\d+',total_strings)[0]\n",
    "total_elements=int(total_elements)/len((soup.find('section',class_=\"PropertiesList_propertiesContainer__HTNbx PropertiesList_listViewGrid__U_BlK\").find_all('div',class_='BasePropertyCard_propertyCardWrap__Z5y4p')))\n",
    "print(f\"Total Pages of consisting of data are: {int(total_elements)}\")\n",
    "\n",
    "pgnumber=1\n",
    "while(pgnumber!=int(total_elements)+1):\n",
    "    # URL of the page we want to scrape.\n",
    "    soup=fetch_url(f\"https://www.realtor.com/realestateandhomes-search/Brownwood_TX/pg-{pgnumber}\")\n",
    "    \n",
    "    if soup != None:\n",
    "        if soup.find('div', class_='BasePropertyCard_propertyCardWrap__Z5y4p') == None:\n",
    "            break    \n",
    "\n",
    "        price=[price_divs for price_divs in soup.find_all('div', class_='Pricestyles__StyledPrice-rui__btk3ge-0 bvgLFe card-price')]\n",
    "        property_dict[\"dict_prices\"].append('N/A' if len(price)==0 else [eachprice.get_text(strip=True) for eachprice in price])\n",
    "        \n",
    "        address_line_1=([ eachaddress_div.find('div', {'data-testid': 'card-address-1'}) for eachaddress_div in soup.find_all('div', class_='card-address truncate-line')])\n",
    "        address_line_1=['N/A' if eachaddress_div is None else eachaddress_div.get_text() for eachaddress_div in address_line_1]\n",
    "        address_line_2=([ eachaddress_div.find('div', {'data-testid': 'card-address-2'}) for eachaddress_div in soup.find_all('div', class_='card-address truncate-line')])\n",
    "        address_line_2=['N/A' if eachaddress_div is None else eachaddress_div.get_text() for eachaddress_div in address_line_2]\n",
    "        address_line=[f\"{address_line_1[count_element]},{address_line_2[count_element]}\" for count_element in range(len(address_line_1))]\n",
    "        property_dict[\"dict_address\"].append(address_line)\n",
    "\n",
    "        property_dict[\"dict_url\"].append(['N/A' if url_div is None else f\"https://www.realtor.com{url_div.find('a', class_='LinkComponent_anchor__0C2xC').get('href')}\"  for url_div in soup.find_all('div', class_='CardContent__StyledCardContent-rui__sc-7ptz1z-0 dsJFdl card-content card-content')])\n",
    "\n",
    "        property_dict[\"dict_broker\"].append(['N/A' if span_tag is None else span_tag.get_text(strip=True) for span_tag in soup.find_all('span', class_='BrokerTitle_titleText__Y8pb0')])\n",
    "            \n",
    "        sqft_li=[property_div for property_div in soup.find_all('ul', class_='PropertyMetastyles__StyledPropertyMeta-rui__sc-1g5rdjn-0 KKDDp card-meta')]\n",
    "        sqft_li=[None if eachsqft_li is None else eachsqft_li.find('li', class_=\"PropertySqftMetastyles__StyledPropertySqftMeta-rui__sc-1gdau7i-0 fnhaOV\") for eachsqft_li in sqft_li]\n",
    "        sqft_li=[None if eachsqft_li is None else eachsqft_li.find('span', {\"aria-hidden\":\"true\"}) for eachsqft_li in sqft_li]\n",
    "        property_dict['dict_sqft'].append([0 if eachsqft_li is None else eachsqft_li.find('span', class_='meta-value').get_text(strip=True) for eachsqft_li in sqft_li])\n",
    "        \n",
    "        acres=[None if property_div is None else property_div.find('li', class_='PropertyLotSizeMetastyles__StyledPropertyLotSizeMeta-rui__sc-1cz4zco-0 cNMyen') for property_div in soup.find_all('ul', class_='PropertyMetastyles__StyledPropertyMeta-rui__sc-1g5rdjn-0 KKDDp card-meta')]\n",
    "        property_dict['dict_acres'].append([0 if property_div is None else property_div.find('span', class_='meta-value').get_text(strip=True) for property_div in acres])\n",
    "         \n",
    "        print(f\"gathered data for {pgnumber} element\\n\")\n",
    "        pgnumber += 1\n",
    "    else:\n",
    "        break\n",
    "print(\"end of fetching data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key,_ in property_dict.items():\n",
    "    property_dict[key]=[x1 for x in property_dict[key] for x1 in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "496\n",
      "496\n",
      "496\n",
      "496\n",
      "496\n",
      "496\n",
      "496\n"
     ]
    }
   ],
   "source": [
    "print(len(property_dict[\"dict_prices\"]))\n",
    "print(len(property_dict[\"dict_address\"]))\n",
    "print(len(property_dict[\"dict_url\"]))\n",
    "print(len(property_dict[\"dict_url\"]))\n",
    "print(len(property_dict[\"dict_broker\"]))\n",
    "print(len(property_dict[\"dict_sqft\"]))\n",
    "print(len(property_dict[\"dict_acres\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  dict_prices                         dict_address dict_sqft dict_acres  \\\n",
      "0     $59,990      Willie B Dr,Brownwood, TX 76801         0       0.31   \n",
      "1     $55,000  2911 Austin Ave,Brownwood, TX 76801         0          0   \n",
      "2     $35,000     Long View Dr,Brownwood, TX 76801         0       0.29   \n",
      "\n",
      "                                            dict_url  \\\n",
      "0  https://www.realtor.com/realestateandhomes-det...   \n",
      "1  https://www.realtor.com/realestateandhomes-det...   \n",
      "2  https://www.realtor.com/realestateandhomes-det...   \n",
      "\n",
      "                                 dict_broker  \n",
      "0                      Brokered by EG Realty  \n",
      "1  Brokered by Houston Interests Real Estate  \n",
      "2                     Brokered by KW Synergy  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame(property_dict)\n",
    "print((df.head(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('FinalData.csv', 'x') as f:\n",
    "    df.to_csv(f, header=True, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "menv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
